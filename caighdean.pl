#!/usr/bin/perl

use strict;
use warnings;
use utf8;
use Memoize;
use Redis;

binmode STDIN, ":utf8";
binmode STDOUT, ":utf8";
binmode STDERR, ":utf8";

my $verbose = 0;
my $unknowns = 0;
my $runtests = 0;
my $extension = '';

for my $a (@ARGV) {
	$verbose = 1 if ($a eq '-v');
	$unknowns = 1 if ($a eq '-u');
	$runtests = 1 if ($a eq '-t');
	$extension = '-gd' if ($a eq '-d');
	$extension = '-gv' if ($a eq '-x');
}

my $maxdepth = 10;
my $penalty = 2.9;
my $tokens = 0;
my $unknown = 0;

my @rules;
my %spurious;
my %cands;
my $redis;

# Keys are strings containing last two processed words, whether
# flushed or not.  If we haven't flushed in a while, the key is usually
# simply the last two words in the hypothesis.
# We just need the last two since these are used to compute the
# most likely *next* word, which only depends on the previous two.
# The value corresponding to the two words is a hashref representing
# the *best* hypothesis with the given two final words.
# The hashref stores the running logprob of the hypothesis
# and an array containing all of the standardizations in the hypothesis...
# this could conceivably be quite long.
# entries in the array are hashrefs that look like:
# {'s' => 'bainríoghan', 't' => 'banríon'}
my %hypotheses;
$hypotheses{''} = {
	'logprob' => 0.0,
	'output' => [],
}; 

sub max {
	(my $a, my $b) = @_;
	return $a if ($a > $b);
	return $b;
}

sub extend_sentence {
	(my $s, my $w) = @_;
	return $w if ($s eq '');
	return "$s $w";
}

sub last_two_words {
	(my $s) = @_;
	if ($s =~ m/ /) {
		$s =~ m/([^ ]+ [^ ]+)$/;
		return $1;
	}
	else {
		return $s;
	}
}

# only used in verbose mode
sub hypothesis_output_string {
	(my $hyp) = @_;
	my $ans = '';
	for my $hr (@{$hyp->{'output'}}) {
		$ans .= $hr->{'t'}." ";
	}
	$ans =~ s/ $//;
	return $ans;
}

# all output is generated by this function; defines the standard
# output format in "pairs":
# Tha => Tá
# mi => mé
# ...
# Argument is a hypothesis (so a hashref with 'logprob' and 'output' keys)
sub hypothesis_pairs_string {
	(my $hyp) = @_;
	my $ans = '';
	for my $hr (@{$hyp->{'output'}}) {
		my $source = $hr->{'s'};
		my $target = $hr->{'t'};
		unless ($source eq $target) {
			$target = irishlc($target) unless ($source =~ m/_/ or $target =~ m/ /);
			$target = recapitalize($target, cap_style($source));
			$source =~ s/([A-Za-zÀÈÌÒÙàèìòùáéíóúÁÉÍÓÚïçÇ'])_/$1 /g;
		}
		$ans .= "$source => $target\n";
	}
	return $ans;
}

# hard-coded N=3 here; "ngram" can come in either empty, a 1-gram, or 2-gram
# this function tacks on $w at the end, but pushes off first word
# in case $ngram starts out as a 2-gram
sub shift_ngram {
	(my $ngram, my $w) = @_;
	my $ans = $ngram;
	$ans .= ' ' unless ($ngram eq '');
	$ans .= $w;
	$ans =~ s/^[^ ]+ // if ($ngram =~ m/ /);
	return $ans;
}

# convert to title case (so leaves "an", etc. untouched)
# can pass a phrase, in which case just first word is affected
# or pass each individual word of a phrase (see $camelcase below)
# second arg is true iff $w == the full token
sub irishtc {
	(my $w, my $start_p) = @_;
	return $w if (!$start_p and $w =~ m/^(an|i|na)$/);
	$w =~ s/^mc(.)/"Mc".uc($1)/e;
	$w =~ s/^o'(.)/"O'".uc($1)/e;
	$w =~ s/^mb/mB/;
	$w =~ s/^gc/gC/;
	$w =~ s/^nd/nD/;
	$w =~ s/^bhf/bhF/;
	$w =~ s/^ng/nG/;
	$w =~ s/^bp/bP/;
	$w =~ s/^ts/tS/;
	$w =~ s/^dt/dT/;
	if ($w =~ m/^h([aeiouáéíóú].*)$/) {
		if ($w =~ m/^h(aigh|allaí?|aló|avá.+|urá|uth)$/) {
			$w =~ s/^h/H/;  # halla -> Halla
		}
		else {
			$w =~ s/^h(.)/'h'.uc($1)/e;  # haimsire -> hAimsire
		}
	}
	$w =~ s/^([nt])-([aeiouáéíóú])/$1.uc($2)/e;
	unless ($w =~ /^[^ ]*\p{Lu}/) {  # if still no cap in first word...
		$w =~ s/^(['-]*)(.)/$1.uc($2)/e;
	}
	return $w;
}

sub recapitalize {
	(my $w, my $n) = @_;
	my $capital_p = $n % 2;
	$n = int($n / 2);
	my $firstcap_p = $n % 2;
	$n = int($n / 2);
	my $camelcase = $n % 2;
	$n = int($n / 2);
	my $allcaps = $n % 2;
	if ($capital_p) {
		if ($firstcap_p) {
			$w = irishtc($w,1);
		}
		else {
			$w =~ s/^([bdm]')([aeiouáéíóú])/$1.uc($2)/e;  # d'Éirinn
			$w =~ s/^(h-?)([aeiouáéíóú])/$1.uc($2)/e;  # hÉireann
			unless ($w =~ /^[^ ]*\p{Lu}/) {  # if still no cap in first word...
				$w = irishtc($w,1);
			}
		}
	}
	if ($camelcase) {
		$w =~ s/([ -])([^ -]*)/$1.irishtc($2,0)/eg;
	}
	if ($allcaps) {
		if ($w =~ m/\p{Ll}.*\p{Lu}/) {
			$w =~ s/^((?:\p{Ll}|['-])*\p{Lu})(.*)$/$1.uc($2)/e;
		}
		else {
			$w = uc($w);
		}
	}
	return $w;
}

# 1st bit: on if "first" letter capitalized (ignoring eclipsis, etc.)
# 2nd bit: on if the actual first letter is capitalized (Tacht but not tAcht)
# 3rd bit: on if camel case; == cap after hyphen (except h-,n-,t-) *or* space
# (only examples where it's mixed are like "Bhaile-an-Easa" - rare)
# 4rd bit: on if all caps (at least 2) after initial eclipsis or whatever.  So:
# 0 = fear, bean, droch-cheann; ~90% of single word tokens in gd/gv/pre-std ga
# 1 = bhFear, h-Árd-rí, 'Sé
# 3 = Droch-chor, Fear, Bean
# 4 = sean-Mháirtín
# 5 = bhFíor-Ghaedhealtacht
# 7 = Nua-Eabhrac, Ard-Easbog
# 9 = gCNOC, h-AIMSIRE
# 11 = FEAR 
# 13 = mBÉAL-OIDEAS
# 15 = SEAN-GHAEDHEAL
# It's important that this work reasonably on pre-standard text,
# Gàidhlig, or Manx, so that, for example,
# h-Éireann is a "regular" capitalized word even w/ hyphen
sub cap_style {
	(my $w) = @_;
	my $ans = 0;
	$ans += 1 if ($w =~ m/^'*((([bdm]|dh)'|[hnt]-?)[AEIOUÁÉÍÓÚÀÈÌÒÙ]|mB|gC|n[DG]|bhF|bP|t-?S|dT|\p{Lu})/);
	$ans += 2 if ($w =~ m/^\p{Lu}/);
	$ans += 4 if ($w =~ m/^...*[_-]\p{Lu}/);
	$ans += 8 if ($w =~ m/^'*(([hnt]-?)[AEIOUÁÉÍÓÚÀÈÌÒÙ]|mB|gC|n[DG]|bhF|bP|t-?S|dT)?(\p{Lu}|['_-])*$/ and $w =~ /\p{Lu}.*\p{Lu}/);
	return $ans;
}

# same as model/tolow.pl
# handles single words and multi-word expressions
sub irishlc {
	(my $w) = @_;
	return $w if ($w =~ /^[<\\]/); # backslash for '\n' only
	$w =~ s/^([nt])([AEIOUÁÉÍÓÚ])/$1-$2/;
	$w =~ s/ ([nt])([AEIOUÁÉÍÓÚ])/ $1-$2/g;
	return lc($w);
}

# whatever we do to corpus in gaeilge/ngram we need to do here!
# unicode apostrophes already handled at STDIN
sub ngram_preprocess {
	(my $w) = @_;
	$w = irishlc($w);
	$w =~ s/^[0-9][0-9,.:]*$/<NUM>/;
	$w =~ s/^.{70}.*$/<LONG>/;
	$w =~ s/^.+:\/\/.*$/<URI>/;
	$w =~ s/^@[A-Za-z0-9_]+$/<USER>/;
	$w =~ s/^[A-Za-z0-9].*@.+$/<EMAIL>/;
	return $w;
}

# only called for n <= maximum stored in the precomputed lang model (usually 3)
# so generically, when called from compute_log_prob, we expect a string 
# say "X Y Z" as an arg, returns log P(Z | X Y).
# If arg is "X Y", we return P(Y | X), and for a word "X", P(X).
# When an ngram was not seen in training, we back off (recursion here)
sub compute_log_prob_helper {
	(my $ngram) = @_;
	my $ans = $redis->get($ngram);
	if (!defined($ans)) {
		if ($ngram =~ m/ /) {  # n>1
			my $start = $ngram;
			$start =~ s/ [^ ]+$//;
			my $tail = $ngram;
			$tail =~ s/^[^ ]+ //;
			$ans = compute_log_prob_helper($tail);
			$redis->select(1);
			my $smfactor = $redis->get($start);
			$redis->select(0);
			$ans += $smfactor if (defined($smfactor));
		}
		else {  # 1-gram
			$ans = $redis->get('<UNSEEN>');
			print STDERR "Warning: prob of unseen token not found in DB\n" unless (defined($ans));
		}
	}
	return $ans;
}

# conditional probability P(X|Y) of seeing k-gram $X
# (k generically == 1, but can be as big as biggest RHS in multi-xx)
# given preceding j-gram $Y (j is almost always == 2, except while
# processing the first couple of words of input, can be 0 or 1!)
# So "$Y $X" is what's in the source text...
sub compute_log_prob {
	(my $X, my $Y) = @_;
	my $ans = 0;
	$Y = '.' if ($Y eq '');
	while ($X =~ m/([^ ]+)/g) {
		my $w = $1;
		my $ngram = extend_sentence($Y, $w);
		$ans += compute_log_prob_helper($ngram);
		$Y = shift_ngram($Y, $w);
	}
	return $ans;
}

# takes non-standard word and returns hashref whose keys are
# candidate standardizations and values the number of rules applied to get there
# Second argument is there because it's recursive.
# Callers should call as: all_matches('focal', 0)
sub all_matches {
	(my $w, my $count) = @_;
	my %ans;
	return \%ans if ($count > $maxdepth);
	if (exists($cands{$w})) {
		for my $std (@{$cands{$w}}) {
			if ($std eq $w) {
				$ans{$std} = $count;
			}
			else {
				$ans{$std} = $count + 1;
			}
		}
	}
	for my $rule (@rules) {
		my $p = $rule->{'patt'};
		if ($w =~ m/$p/) {
			my $r = $rule->{'repl'};
			my $cand = $w;
			$cand =~ s/$p/$r/eeg;
			my $subcount = $count;
			$subcount++ unless ($rule->{'level'} == -1);
			my $subans = all_matches($cand, $subcount);
			for my $a (keys %{$subans}) {
				next if (exists($spurious{"$w $a"}));
				if (exists($ans{$a})) {  # if already found some other way
					$ans{$a} = $subans->{$a} if ($subans->{$a} < $ans{$a});
				}
				else {
					$ans{$a} = $subans->{$a};
				}
			}
			# rule produces multiword: oidhche-sin => oidhche_sin
			if ($cand =~ m/^([^_]+)_(.+)$/ and scalar keys %ans == 0) {
				my $left = $1;
				my $right = $2;
				my $subans_l = all_matches($left, $subcount);
				my $subans_r = all_matches($right, $subcount);
				for my $a (keys %{$subans_l}) {
					for my $b (keys %{$subans_r}) {
						$ans{"$a $b"} = max($subans_l->{$a}, $subans_r->{$b});
					}
				}
			}
		}
	}
	return \%ans;
}

sub load_databases {
	print "Loading rules file...\n" if $verbose;
	open(RULES, "<:utf8", "rules$extension.txt") or die "Could not open spelling rules file: $!";
	while (<RULES>) {
		next if (/^#/);
		chomp;
		my %rule;
		m/^(\S+)\t(\S+)\t([0-9-]+)$/;
		$rule{'patt'} = qr/$1/;
		$rule{'level'} = $3;
		my $repl = $2;
		$repl =~ s/(.+)/"$1"/;
		$rule{'repl'} = $repl;
		push @rules, \%rule;
	}
	close RULES;

	print "Loading spurious pairs...\n" if $verbose;
	open(SPURIOUS, "<:utf8", "spurious$extension.txt") or die "Could not open list of spurious pairs: $!";
	while (<SPURIOUS>) {
		chomp;
		$spurious{$_}++;
	}
	close SPURIOUS;

	print "Loading clean word list...\n" if $verbose;
	open(CLEAN, "<:utf8", "clean.txt") or die "Could not open clean wordlist: $!";
	while (<CLEAN>) {
		chomp;
		push @{$cands{$_}}, $_ unless (exists($spurious{"$_ $_"}));
	}
	close CLEAN;

	print "Loading list of pairs...\n" if $verbose;
	open(PAIRS, "<:utf8", "pairs$extension.txt") or die "Could not open list of pairs: $!";
	while (<PAIRS>) {
		chomp;
		next if exists($spurious{$_});
		m/^([^ ]+) (.+)$/;
		push @{$cands{$1}}, $2;
	}
	close PAIRS;

	print "Loading multi-word phrase pairs...\n" if $verbose;
	open(MULTI, "<:utf8", "multi$extension.txt") or die "Could not open list of phrases: $!";
	while (<MULTI>) {
		chomp;
		m/^([^ ]+) (.+)$/;
		my $source = $1;
		my $target = $2;
		push @{$cands{$source}}, $target;
		if ($source =~ m/\p{Lu}/) {
			push @{$cands{lc($source)}}, irishlc($target);
		}
	}
	close MULTI;

	print "Loading local pairs...\n" if $verbose;
	open(LOCALPAIRS, "<:utf8", "pairs-local$extension.txt") or die "Could not open list of local pairs: $!";
	while (<LOCALPAIRS>) {
		chomp;
		if (exists($spurious{$_})) {
			print STDERR "Warning: pair \"$_\" is in pairs-local and spurious\n"; 	
		}
		m/^([^ ]+) (.+)$/;
		push @{$cands{$1}}, $2;
	}
	close LOCALPAIRS;

	eval {$redis = Redis->new;}; # default is 127.0.0.1:6379
	die "Unable to connect to Redis server" if $@;
}

# pass hashref in vs. using global %hypotheses
sub flush_best_hypothesis {
	(my $hashref) = @_;
	my $bestlogprob = -9999;
	my $bestkey;
	print "Flushing best of ".scalar(keys %{$hashref})." hypotheses\n" if ($verbose);
	for my $k (keys %{$hashref}) {
		if ($hashref->{$k}->{'logprob'} > $bestlogprob) {
			$bestlogprob = $hashref->{$k}->{'logprob'};
			$bestkey = $k;
		}
	}
	print "FLUSH:\n" if ($verbose);
	print hypothesis_pairs_string($hashref->{$bestkey});
	$hashref->{$bestkey} = {
		'logprob' => 0.0,
		'output' => [],
	}; 
}

sub process_ignorable_token {
	(my $tok) = @_;

	print "Processing ignorable: $tok\n" if $verbose;
	for my $two (keys %hypotheses) {
		push @{$hypotheses{$two}->{'output'}}, {'s' => $tok, 't' => $tok};
	}
}

sub process_one_token {
	(my $tok) = @_;

	$tokens++;
	my %newhypotheses;
	my $hashref = all_matches($tok, 0);
	my $unknown_p = (scalar keys %{$hashref} == 0);

	# if there were no matches in %cands, and none computed
	# by applying rules, then leave the token unchanged
	if ($unknown_p) {
		$hashref->{$tok} = 0;
		$unknown++;
		print "UNKNOWN: $tok\n" if $verbose;
		if ($unknowns) {
			print "$tok\n";
			delete $hashref->{$tok};
		}
	}
	return if ($unknowns);

	print "Input token = $tok\n" if $verbose;
	for my $x (keys %{$hashref}) {
		my $normalized_x = ngram_preprocess($x);
		print "Possible standardization: $x, normalized: $normalized_x\n" if $verbose;
		for my $two (keys %hypotheses) {
			my @newoutput = @{$hypotheses{$two}->{'output'}};
			push @newoutput, {'s' => $tok, 't' => $x};
			my $tail = extend_sentence($two, $normalized_x);
			my $candlogprob = compute_log_prob($normalized_x, $two);
			my %newhyp = (
				'logprob' => $hypotheses{$two}->{'logprob'} + $candlogprob - $penalty*$hashref->{$x},
				'output' => \@newoutput,
			);
			if ($verbose) {
				print "Created a new hypothesis (".$newhyp{'logprob'}."): ".hypothesis_output_string(\%newhyp)."\n";
				print "Computed from logprob of best hypothesis with key $two: ".$hypotheses{$two}->{'logprob'}."\n";
				print "Plus logprob of n-gram: $tail ($candlogprob)\n";
				print "Minus penalty $penalty times ".$hashref->{$x}."\n";
			}
			my $newtwo = last_two_words($tail);
			if (exists($newhypotheses{$newtwo})) {
				# need only keep the best among those ending w/ these two words
				if ($newhypotheses{$newtwo}->{'logprob'} < $newhyp{'logprob'}) {
					$newhypotheses{$newtwo} = \%newhyp;
					print "And it's the best so far ending in: $newtwo\n" if $verbose;
				}
				else {
					print "But not as good as (".$newhypotheses{$newtwo}->{'logprob'}."): ".hypothesis_output_string($newhypotheses{$newtwo})."\n" if $verbose;
				}
			}
			else {
				$newhypotheses{$newtwo} = \%newhyp;
				print "And it's the first (hence best) so far ending in: $newtwo\n" if $verbose;
			}
		}
	}

	# if there's only one hypothesis left, we can flush output and reset
	flush_best_hypothesis(\%newhypotheses) if (scalar keys %newhypotheses == 1);
	%hypotheses = %newhypotheses;

	if ($verbose) {
		print "Live hypotheses:\n";
		for my $two (keys %hypotheses) {
			print "Hypothesis with key '$two' (".$hypotheses{$two}->{'logprob'}."): ".hypothesis_output_string($hypotheses{$two})."\n";
		}
	}
	# when evaluating, don't want to memoize the fake answer for unknown tokens
	delete $hashref->{$tok} if ($verbose and $unknown_p);
}

sub normalize_apost_and_dash {
	(my $w) = @_;
	if ($w =~ m/[a-zA-ZáéíóúÁÉÍÓÚàèìòùÀÈÌÒÙ]/) {
		$w =~ s/[ʼ’]/'/g;
		$w =~ s/[‐‑]/-/g;  # U+2010, U+2011 to ASCII
	}
	return $w;
}

sub translate_stdin {
	print "Ready.\n" if $verbose;
	while (<STDIN>) {
		chomp;
		# skip SGML markup+newlines, only things to completely ignore in n-gram model
		# can match other "special" tokens with [:@&;=,.] which should all
		# remain unchanged, but are part of n-gram model
		if ($_ eq '\n' or /^<.+>$/) {
			process_ignorable_token($_);
		}
		elsif (/^['ʼ’]/ or /['ʼ’]$/) {
			my $w = normalize_apost_and_dash($_);
			if (exists($cands{$w}) or m/^['ʼ’]+$/ or
				($w =~ m/^'*[A-ZÁÉÍÓÚÀÈÌÒÙ]/ and exists($cands{lc($w)}))) {
				process_one_token($w);
			}
			else {
				m/^(['ʼ’]*)(.*[^'ʼ’])(['ʼ’]*)$/;
				process_one_token($1) if ($1 ne '');
				process_one_token(normalize_apost_and_dash($2)) if ($2 ne '');
				process_one_token($3) if ($3 ne '');
			}
		}
		else {
			process_one_token(normalize_apost_and_dash($_));
		}
	}

	flush_best_hypothesis(\%hypotheses) unless ($unknowns);

	if ($verbose) {
		print "Total tokens: $tokens\n";
		print "Unknown tokens: $unknown\n";
		if ($tokens > 0) {
			my $frac = $unknown / (1.0 * $tokens);
			print "Fraction unknown: $frac\n";
		}
	}
}

sub assert {
	(my $bool_expr, my $number, my $comment) = @_;
	if ($bool_expr) {
		print "ok $number - $comment\n" if $verbose;
	}
	else {
		print "not ok $number - $comment\n";
	}
	return $bool_expr;
}

sub run_unit_tests {
	my $testnum = 1;
	assert(irishtc('an',0) eq 'an',$testnum++,'irishtc of function word in camel case');
	assert(irishtc('na',0) eq 'na',$testnum++,'irishtc of function word in camel case');
	assert(irishtc('mbaile',0) eq 'mBaile',$testnum++,'irishtc of eclipsed word in camel case');
	assert(irishtc('mbaile',1) eq 'mBaile',$testnum++,'irishtc of eclipsed word');
	assert(irishtc('an',1) eq 'An',$testnum++,'irishtc of function word at start');
	assert(irishtc('mccartney',1) eq 'McCartney',$testnum++,'irishtc of Mc surname');
	assert(irishtc("o'reilly",1) eq "O'Reilly",$testnum++,'irishtc of O surname');
	assert(irishtc('an bhean',1) eq 'An bhean',$testnum++,'irishtc of a typical MWE');
	assert(irishtc('n-oileán',1) eq 'nOileán',$testnum++,'irishtc requiring dropped hyphen after n');
	assert(irishtc('t-aire',1) eq 'tAire',$testnum++,'irishtc requiring dropped hyphen after t');
	assert(irishtc('r-phost',1) eq 'R-phost',$testnum++,'irishtc where we do not drop hyphen');
	assert(irishlc('ABC') eq 'abc',$testnum++,'irishlc of all capital word');
	assert(irishlc('Gaeilge') eq 'gaeilge',$testnum++,'irishlc of typical capitalized word');
	assert(irishlc('bean') eq 'bean',$testnum++,'irishlc of already-lowercase word');
	assert(irishlc('nOileán') eq 'n-oileán',$testnum++,'irishlc requiring inserted hyphen');
	assert(irishlc('tAire') eq 't-aire',$testnum++,'irishlc requiring inserted hyphen after t');
	assert(irishlc('<P>') eq '<P>',$testnum++,'irishlc should not lowercase markup');
	assert(irishlc('<a href="http://example.com/Tfij45R">') eq '<a href="http://example.com/Tfij45R">',$testnum++,'irishlc should not lowercase any attributes either');
	assert(irishlc('Cósta Ríce') eq 'cósta ríce',$testnum++,'irishlc of MWE');
	assert(irishlc('Cré na nAspal') eq 'cré na n-aspal',$testnum++,'irishlc of MWE requiring inserted hyphen');
	assert(irishlc('a Ċaoiṁín') eq 'a ċaoiṁín',$testnum++,'irishlc of dotted consonants');
# extend_sentence
# last_two_words
# shift_ngram
# recapitalize
# cap_style
# ngram_preprocess
# normalize_apost_and_dash
}

if ($runtests) {
	run_unit_tests();
}
else {
	memoize('compute_log_prob');
	memoize('all_matches');
	load_databases();
	translate_stdin();
}

exit 0;
